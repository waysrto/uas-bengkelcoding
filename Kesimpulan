### Kesimpulan Hasil Pemodelan

1. Model Gradient Boosting:
   - Akurasi (Raw dan Normalized): 67%.
   - Confusion Matrix menunjukkan model ini cukup baik membedakan kelas dengan akurasi yang moderat, namun masih terdapat kesalahan klasifikasi yang signifikan, terutama dalam mendeteksi kelas minoritas (`Potability = 1`).

2. Model Random Forest:
   - Akurasi (Raw dan Normalized): 84%.
   - Confusion Matrix menunjukkan model ini bekerja jauh lebih baik dibandingkan Gradient Boosting, dengan kemampuan mendeteksi kedua kelas lebih akurat.
   - Model ini menghasilkan performa terbaik dibandingkan yang lain.

3. Model SVM:
   - Akurasi Raw: 49% (tanpa normalisasi).
   - Akurasi Normalized: 67% (setelah normalisasi).
   - Hasil ini menunjukkan bahwa SVM sangat bergantung pada normalisasi data. Tanpa normalisasi, performanya sangat rendah karena sifat algoritma yang sensitif terhadap skala fitur.


### Mengapa Gradient Boosting dan Random Forest Memiliki Akurasi Sama Sebelum dan Sesudah Normalisasi?**

1. Gradient Boosting:
   - Gradient Boosting adalah model berbasis pohon keputusan yang tidak sensitif terhadap skala data. Artinya, fitur tidak perlu dinormalisasi untuk memengaruhi performa model.
   - Karena itu, normalisasi tidak berdampak pada akurasi maupun matriks kebingungan.

2. Random Forest:
   - Sama seperti Gradient Boosting, Random Forest juga berbasis pohon keputusan. Model ini mengevaluasi split data berdasarkan ranking fitur, bukan nilai numerik absolut.
   - Oleh karena itu, normalisasi juga tidak berdampak pada performa model.


### Catatan untuk Model SVM
- SVM sangat sensitif terhadap skala fitur karena algoritmanya bekerja berdasarkan jarak antar data (margin).
- Normalisasi memastikan semua fitur memiliki kontribusi yang seimbang dalam menentukan hyperplane, sehingga performa meningkat signifikan.

1. Gradient Boosting:
   - Keunggulan:
     - Dapat mengatasi berbagai jenis data dan hubungan non-linear dengan sangat baik.
     - Membuat model yang kuat dengan menggunakan ensemble dari model-model sederhana (decision trees).
     - Dapat mengoptimalkan kesalahan dengan fokus pada data yang sulit diprediksi.
   - Keterbatasan:
     - Rentan terhadap overfitting jika tidak disetel dengan baik (hyperparameter tuning sangat penting).
     - Proses pelatihan yang lebih lambat dibandingkan dengan beberapa algoritma lain.
     - Memerlukan waktu lebih lama dalam proses training, terutama untuk dataset yang besar.

2. Random Forest:
   - Keunggulan:
     - Cenderung lebih tahan terhadap overfitting, terutama dengan dataset yang besar.
     - Dapat menangani data yang hilang dengan cukup baik.
     - Proses training lebih cepat dibandingkan dengan Gradient Boosting.
     - Dapat memberikan estimasi fitur penting yang dapat digunakan untuk analisis lebih lanjut.
   - Keterbatasan:
     - Modelnya bisa menjadi lebih besar dan sulit untuk diinterpretasi jika jumlah pohon yang digunakan sangat banyak.
     - Meskipun lebih stabil, Random Forest mungkin kurang akurat dibandingkan dengan model-model yang lebih terfokus seperti Gradient Boosting pada beberapa kasus.

3. SVM (Support Vector Machine):
   - Keunggulan:
     - Efektif untuk data dengan dimensi tinggi (high-dimensional data).
     - Kuat dalam menangani kasus-kasus dengan margin keputusan yang jelas antara kelas.
     - Dapat digunakan untuk data non-linear dengan kernel yang sesuai.
   - Keterbatasan:
     - Tidak bekerja dengan baik pada dataset besar atau dengan banyak data noise.
     - Parameter yang digunakan (seperti kernel dan regularization) perlu disetel dengan sangat hati-hati.
     - Proses pelatihan bisa memakan waktu lama untuk dataset besar, dan membutuhkan memori yang cukup banyak.


Rekomendasi Algoritma yang Paling Efektif:

Berdasarkan hasil evaluasi yang diberikan, Random Forest menjadi algoritma yang paling efektif untuk kasus ini. 

- Alasan mengapa Random Forest optimal:
  - Akurasinya lebih tinggi (0.84) dibandingkan dengan Gradient Boosting (0.67) dan SVM (0.49/0.67).
  - Stabilitas: Random Forest lebih stabil dalam hal akurasi, dan tidak rentan terhadap overfitting jika dibandingkan dengan Gradient Boosting, yang cenderung lebih sensitif terhadap pengaturan hyperparameter.
  - Kemudahan Implementasi: Dibandingkan dengan SVM, Random Forest lebih mudah untuk diimplementasikan dan memerlukan lebih sedikit tuning dibandingkan dengan Gradient Boosting.
  
